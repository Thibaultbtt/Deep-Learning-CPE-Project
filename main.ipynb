{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modèle pour la détermination du type de véhicule\n",
    "\n",
    "### 1. Préparation des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crop provisoire des images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "def crop_images (dossier_crops, dossier_coordonnees, dossier_images) :\n",
    "    # Obtenir les listes triées des fichiers dans les dossiers\n",
    "    fichiers_images = sorted(os.listdir(dossier_images))\n",
    "    fichiers_coordonnees = sorted(os.listdir(dossier_coordonnees))\n",
    "\n",
    "    # Vérifier si les deux dossiers ont le même nombre de fichiers\n",
    "    if len(fichiers_images) != len(fichiers_coordonnees):\n",
    "        print(\"Le nombre de fichiers dans les deux dossiers ne correspond pas.\")\n",
    "        exit()\n",
    "\n",
    "    # Parcours des images et fichiers de coordonnées\n",
    "    for index, image_file in enumerate(fichiers_images):\n",
    "        if image_file.endswith(('.png', '.jpg', '.jpeg')):\n",
    "            image_path = os.path.join(dossier_images, image_file)\n",
    "            coord_file = os.path.join(dossier_coordonnees, fichiers_coordonnees[index])\n",
    "            \n",
    "            # Charger l'image\n",
    "            with Image.open(image_path) as img:\n",
    "                img_width, img_height = img.size  # Taille de l'image\n",
    "                # Lire les coordonnées\n",
    "                with open(coord_file, \"r\") as file:\n",
    "                    lines = file.readlines()\n",
    "                    for i, line in enumerate(lines):\n",
    "                        data = line.strip().split()\n",
    "                        \n",
    "                        # Vérifier la validité des données\n",
    "                        if len(data) < 9:\n",
    "                            print(f\"Coordonnées invalides dans {coord_file}, ligne {i + 1}\")\n",
    "                            continue\n",
    "\n",
    "                        img_type = data[-2]\n",
    "\n",
    "                        # Calcul des coordonnées absolues du rectangle (x_min, y_min, x_max, y_max)\n",
    "                        x_min = int(round(float(data[2])))\n",
    "                        y_min = int(round(float(data[1])))\n",
    "                        x_max = int(round(float(data[0])))\n",
    "                        y_max = int(round(float(data[5])))\n",
    "\n",
    "                        # Découper l'image\n",
    "                        cropped_img = img.crop((x_min, y_min, x_max, y_max))\n",
    "                        \n",
    "                        # Sauvegarder l'image cropée\n",
    "                        crop_file_name = f\"{img_type}_{index + 1}_{i + 1}.jpg\"\n",
    "                        crop_path = os.path.join(dossier_crops, crop_file_name)\n",
    "                        cropped_img.save(crop_path, \"JPEG\")\n",
    "                        #print(f\"Image cropée enregistrée : {crop_path}\")\n",
    "                        #Nom d'origine : {image_file}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformation : Niveau de gris sur tout le dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, os\n",
    "\n",
    "#change_to_gray_input_folder = './result'\n",
    "#change_to_gray_output_folder = './gray_images'\n",
    "\n",
    "def change_to_gray (input_folder, output_folder) :\n",
    "    \"\"\"\n",
    "    Transforme une image à l'origine en couleur en niveaux de gris\n",
    "    \"\"\"\n",
    "    for image_name in os.listdir(input_folder) :\n",
    "        img = cv2.imread(f'./cropped_images/{image_name}')\n",
    "        grayFrame = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        output_path = os.path.join(output_folder, image_name)\n",
    "        cv2.imwrite(output_path, grayFrame)\n",
    "    #print(f'End of the process Color to Gray.\\nFind the images in the folder {output_folder}')\n",
    "\n",
    "#change_to_gray (change_to_gray_input_folder, change_to_gray_output_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformation : ajout de bruit gaussien sur les images pour simuler une caméra de mauvaise qualité"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import random\n",
    "\n",
    "def add_gaussian_noise(img, mean=0, std=25):\n",
    "    \"\"\"\n",
    "    Ajoute un bruit gaussien à une image.\n",
    "    \"\"\"\n",
    "    # Convertir l'image en tableau numpy\n",
    "    img_array = np.array(img, dtype=np.float32)\n",
    "\n",
    "    # Générer du bruit gaussien\n",
    "    std = 10\n",
    "    noise = np.random.normal(mean, std, img_array.shape)\n",
    "    noisy_img = img_array + noise\n",
    "\n",
    "    # Limiter les valeurs entre 0 et 255\n",
    "    noisy_img = np.clip(noisy_img, 0, 255).astype(np.uint8)\n",
    "    return noisy_img\n",
    "\n",
    "def process_images_with_effects(source_dir, target_dir, apply_blur=True, apply_noise=True):\n",
    "    \"\"\"\n",
    "    Applique flou et bruit aux images redimensionnées.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(target_dir):\n",
    "        os.makedirs(target_dir)\n",
    "\n",
    "    for filename in os.listdir(source_dir):\n",
    "        if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp')):\n",
    "            file_path = os.path.join(source_dir, filename)\n",
    "            save_path = os.path.join(target_dir, filename)\n",
    "\n",
    "            # Charger l'image\n",
    "            with Image.open(file_path) as img:\n",
    "                # Convertir en BGR pour OpenCV\n",
    "                img_cv = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)\n",
    "\n",
    "                # Appliquer bruit gaussien\n",
    "                if apply_noise and random.random() > 0.3:  # 50% de chances d'ajouter du bruit\n",
    "                    img_cv = add_gaussian_noise(img_cv, mean=0, std=random.randint(15, 40))\n",
    "\n",
    "                # Convertir en RGB et sauvegarder\n",
    "                final_img = Image.fromarray(cv2.cvtColor(img_cv, cv2.COLOR_BGR2RGB))\n",
    "                final_img.save(save_path)\n",
    "                #print(f\"Processed and saved: {save_path}\")\n",
    "\n",
    "# # Répertoires\n",
    "# source_directory = \"./gray_images\"  # Changez avec votre chemin\n",
    "# target_directory = \"./noise_images\"  # Répertoire cible\n",
    "\n",
    "# # Appliquer flou et bruit\n",
    "# process_images_with_effects(source_directory, target_directory, apply_blur=True, apply_noise=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformation : Redimensionnement pour que les images soient environ de la taille de la médiane des tailles des exemples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def calculate_median_size(image_paths):\n",
    "    \"\"\"Calcul la médiane des tailles (largeur, hauteur) des images.\"\"\"\n",
    "    dimensions = []\n",
    "    for path in image_paths:\n",
    "        with Image.open(path) as img:\n",
    "            dimensions.append(img.size)  # (width, height)\n",
    "    dimensions = np.array(dimensions)\n",
    "    median_width = int(np.median(dimensions[:, 0]))\n",
    "    median_height = int(np.median(dimensions[:, 1]))\n",
    "    return median_width, median_height\n",
    "\n",
    "def add_random_variation(size, variation_percent=0.2):\n",
    "    \"\"\"\n",
    "    Ajoute une variation aléatoire à une taille donnée.\n",
    "    \"\"\"\n",
    "    factor = 1 + random.uniform(-variation_percent, variation_percent)\n",
    "    return int(size * factor)\n",
    "\n",
    "def resize_image_with_aspect_ratio(img, target_width, target_height):\n",
    "    \"\"\"\n",
    "    Redimensionne une image en conservant le ratio d'aspect, en s'adaptant à la taille cible.\n",
    "    \"\"\"\n",
    "    original_width, original_height = img.size\n",
    "    aspect_ratio = original_width / original_height\n",
    "\n",
    "    # Ajuster la largeur et la hauteur pour conserver le ratio\n",
    "    if target_width / target_height > aspect_ratio:\n",
    "        # Ajuste par la hauteur\n",
    "        new_height = target_height\n",
    "        new_width = int(new_height * aspect_ratio)\n",
    "    else:\n",
    "        # Ajuste par la largeur\n",
    "        new_width = target_width\n",
    "        new_height = int(new_width / aspect_ratio)\n",
    "\n",
    "    try :\n",
    "        return img.resize((new_width, new_height), Image.ANTIALIAS)\n",
    "    except :\n",
    "        return img.resize((new_width, new_height), Image.Resampling.LANCZOS)\n",
    "\n",
    "def resize_images(source_dir, target_dir, median_size, variation_percent=0.2):\n",
    "    \"\"\"\n",
    "    Redimensionne les images en conservant leur ratio d'aspect, avec des tailles légèrement différentes.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(target_dir):\n",
    "        os.makedirs(target_dir)\n",
    "\n",
    "    for filename in os.listdir(source_dir):\n",
    "        if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp')):\n",
    "            file_path = os.path.join(source_dir, filename)\n",
    "            with Image.open(file_path) as img:\n",
    "                # Ajouter une variation aléatoire aux dimensions médianes\n",
    "                target_width = add_random_variation(median_size[0], variation_percent)\n",
    "                target_height = add_random_variation(median_size[1], variation_percent)\n",
    "\n",
    "                # Redimensionner en conservant le ratio d'aspect\n",
    "                resized_img = resize_image_with_aspect_ratio(img, target_width, target_height)\n",
    "\n",
    "                # Sauvegarder l'image redimensionnée\n",
    "                save_path = os.path.join(target_dir, filename)\n",
    "                resized_img.save(save_path)\n",
    "                #print(f\"Resized and saved: {save_path} -> {resized_img.size}\")\n",
    "\n",
    "# # Répertoires\n",
    "# source_directory = \"./noise_images\"  # Changez avec votre chemin\n",
    "# target_directory = \"./resized_images\"  # Répertoire cible\n",
    "\n",
    "# dimension_images = \"./AlgorithmePreProcess/dimension_images\"\n",
    "\n",
    "# # Images avec tailles définies\n",
    "# defined_images = [os.path.join(dimension_images, f) for f in os.listdir(dimension_images)\n",
    "#                   if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp'))]\n",
    "\n",
    "# # Calcul de la taille médiane\n",
    "# median_size = calculate_median_size(defined_images)\n",
    "\n",
    "# # Redimensionnement des images avec une variation aléatoire de ±20 %\n",
    "# resize_images(source_directory, target_directory, median_size, variation_percent=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformation : UpSampling en retournant les images aléatoirement\n",
    "Tous les exemples uniques de rotation/flip d'image :\n",
    "\n",
    "| Rotation (k) | Flip Horizontal | Flip Vertical |\n",
    "|--------------|-----------------|---------------|\n",
    "| 0            | False           | False         |\n",
    "| 0            | True            | False         |\n",
    "| 0            | False           | True          |\n",
    "| 1            | False           | False         |\n",
    "| 1            | True            | False         |\n",
    "| 2            | False           | False         |\n",
    "| 2            | True            | False         |\n",
    "| 3            | False           | False         |\n",
    "| 3            | True            | False         |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# def random_rotate_image(opencv_img):\n",
    "#     img = tf.convert_to_tensor(opencv_img, dtype=tf.float32)\n",
    "#     k = random.randint(1, 3)  # 1 = 90°, 2 = 180°, 3 = 270°\n",
    "#     img = tf.image.rot90(img, k=k)\n",
    "#     if k != 4:\n",
    "#         img = tf.image.random_flip_left_right(img)\n",
    "#         img = tf.image.random_flip_up_down(img)\n",
    "\n",
    "#     img_rotated = img.numpy().astype(np.uint8)\n",
    "#     return img_rotated\n",
    "\n",
    "unique_combinations = [\n",
    "    # (0, False, False), ==> Image de base : (nb de flip à 90°, mirroir horizontal, mirroir veritcal)\n",
    "    (0, True, False),\n",
    "    (0, False, True),\n",
    "    (1, False, False),\n",
    "    (1, True, False),\n",
    "    (2, False, False),\n",
    "    (2, True, False),\n",
    "    (3, False, False),\n",
    "    (3, True, False)\n",
    "]\n",
    "\n",
    "def apply_transformations(img, rotation_count, flip_horizontal, flip_vertical):\n",
    "    \"\"\"\n",
    "    Applique une transformation à l'image selon le nombre de rotations et les flips.\n",
    "    \"\"\"\n",
    "    img = tf.convert_to_tensor(img, dtype=tf.float32)\n",
    "\n",
    "    img = tf.image.rot90(img, k=rotation_count)\n",
    "\n",
    "    # Appliquer les flips\n",
    "    if flip_horizontal:\n",
    "        img = tf.image.flip_left_right(img)\n",
    "    if flip_vertical:\n",
    "        img = tf.image.flip_up_down(img)\n",
    "\n",
    "    img_rotated = img.numpy().astype(np.uint8)\n",
    "    return img_rotated\n",
    "\n",
    "def rotate_images (output_folder) :\n",
    "    for image_name in os.listdir('./resized_images') :\n",
    "        img = cv2.imread(f'./resized_images/{image_name}')\n",
    "\n",
    "        # On choisit deux transformations aléatoires\n",
    "        random_choice1 = random.choice(unique_combinations)\n",
    "        random_choice2 = random.choice(unique_combinations)\n",
    "\n",
    "        # On vérifie que les choix sont différents\n",
    "        while random_choice1 == random_choice2:\n",
    "            random_choice2 = random.choice(unique_combinations)\n",
    "\n",
    "        rotation_count1, flip_horizontal1, flip_vertical1 = random_choice1\n",
    "        rotation_count2, flip_horizontal2, flip_vertical2 = random_choice2\n",
    "\n",
    "        rotations_list = [apply_transformations(img, rotation_count1, flip_horizontal1, flip_vertical1), \n",
    "                        apply_transformations(img, rotation_count2, flip_horizontal2, flip_vertical2)]\n",
    "        \n",
    "\n",
    "        img_name = os.path.splitext(image_name)[0]\n",
    "        category = img_name.split(\"_\")[0]\n",
    "        output_path = os.path.join(output_folder + f'{category}/', f\"{img_name}.png\")\n",
    "        cv2.imwrite(output_path, img)\n",
    "\n",
    "        for i, rotated_image in enumerate(rotations_list) :\n",
    "            output_image_name = f\"{img_name}_{i+1}.png\"\n",
    "            output_path = os.path.join(output_folder + f'{category}/', output_image_name)\n",
    "            cv2.imwrite(output_path, rotated_image)\n",
    "\n",
    "        # for i, rotated_image in enumerate(rotations_list) :\n",
    "        #     img_name = os.path.splitext(image_name)[0]\n",
    "        #     category = img_name.split(\"_\")[0]\n",
    "        #     output_image_name = f\"{img_name}_{i+1}.png\"\n",
    "        #     output_path = os.path.join(output_folder + f'{category}/', output_image_name)\n",
    "        #     cv2.imwrite(output_path, rotated_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = cv2.imread(f'./resized_images/cars_2_1.jpg')\n",
    "# img = tf.convert_to_tensor(img, dtype=tf.float32)\n",
    "# img = tf.image.rot90(img, k=2)\n",
    "# img = tf.image.random_flip_up_down(img)\n",
    "# img_rotated = img.numpy().astype(np.uint8)\n",
    "# output_folder = './TEST_ROTATION'\n",
    "# os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# output_image_name = f\"car_2_rotated_flip.png\"\n",
    "# output_path = os.path.join(output_folder, output_image_name)\n",
    "# cv2.imwrite(output_path, img_rotated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Version finale de la préparation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "Image.MAX_IMAGE_PIXELS = None  # Supprime complètement la limite\n",
    "\n",
    "def prepare_data (output_folder , mode) :\n",
    "    print(f'Beginning of the preparation process for {mode} data.\\n')\n",
    "\n",
    "    # Chemins des dossiers\n",
    "    dossier_images = f\"./dataset_part_2/{mode}/images\"  # Chemin vers le dossier contenant les images\n",
    "    dossier_coordonnees = f\"./dataset_part_2/{mode}/labelTxt\"  # Chemin vers le dossier contenant les fichiers de coordonnées\n",
    "    dossier_crops = \"./cropped_images\"  # Dossier de sortie pour les images cropées\n",
    "\n",
    "    #os.makedirs(output_folder, exist_ok=True)\n",
    "    # Créer le dossier de sortie s'il n'existe pas\n",
    "    os.makedirs(dossier_crops, exist_ok=True)\n",
    "    crop_images (dossier_crops, dossier_coordonnees, dossier_images)\n",
    "    ### la partie au dessus sert à croper provisoirement. Elle sera à enlever plus tard.\n",
    "\n",
    "    os.makedirs(\"./gray_images\", exist_ok=True)\n",
    "    change_to_gray_input_folder = './cropped_images'\n",
    "    change_to_gray_output_folder = './gray_images'\n",
    "    change_to_gray (change_to_gray_input_folder, change_to_gray_output_folder)\n",
    "    shutil.rmtree('./cropped_images')\n",
    "    print(f'End of the process Color to Gray')\n",
    "\n",
    "    # Répertoires\n",
    "    os.makedirs(\"./noise_images\", exist_ok=True)\n",
    "    source_directory = \"./gray_images\"\n",
    "    target_directory = \"./noise_images\"\n",
    "\n",
    "    # Appliquer flou et bruit\n",
    "    process_images_with_effects(source_directory, target_directory, apply_blur=True, apply_noise=True)\n",
    "    print(f'End of the process Add Effects on Images')\n",
    "    shutil.rmtree('./gray_images')\n",
    "\n",
    "    # Répertoires\n",
    "    os.makedirs(\"./resized_images\", exist_ok=True)\n",
    "    source_directory = \"./noise_images\"\n",
    "    target_directory = \"./resized_images\"\n",
    "    dimension_images = \"./AlgorithmePreProcess/dimension_images\"\n",
    "\n",
    "    # Images avec tailles définies\n",
    "    defined_images = [os.path.join(dimension_images, f) for f in os.listdir(dimension_images)\n",
    "                    if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp'))]\n",
    "\n",
    "    # Calcul de la taille médiane\n",
    "    median_size = calculate_median_size(defined_images)\n",
    "\n",
    "    # Redimensionnement des images avec une variation aléatoire de ±20 %\n",
    "    resize_images(source_directory, target_directory, median_size, variation_percent=0.2)\n",
    "    print(f'End of the process Resize Images')\n",
    "    shutil.rmtree('./noise_images')\n",
    "\n",
    "    # Génération d'images tournées dans des sens différents\n",
    "    rotate_images (output_folder)\n",
    "    print(f'End of the process Random Turn Images')\n",
    "    shutil.rmtree('./resized_images')\n",
    "\n",
    "    print(f'\\nEnd of the Preparation process')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning of the preparation process for train data.\n",
      "\n",
      "End of the process Color to Gray\n",
      "End of the process Add Effects on Images\n",
      "End of the process Resize Images\n",
      "End of the process Random Turn Images\n",
      "\n",
      "End of the Preparation process\n",
      "Beginning of the preparation process for test data.\n",
      "\n",
      "End of the process Color to Gray\n",
      "End of the process Add Effects on Images\n",
      "End of the process Resize Images\n",
      "End of the process Random Turn Images\n",
      "\n",
      "End of the Preparation process\n",
      "Beginning of the preparation process for validation data.\n",
      "\n",
      "End of the process Color to Gray\n",
      "End of the process Add Effects on Images\n",
      "End of the process Resize Images\n",
      "End of the process Random Turn Images\n",
      "\n",
      "End of the Preparation process\n"
     ]
    }
   ],
   "source": [
    "train_output_folder = './train_prepared_images/'\n",
    "test_output_folder = './test_prepared_images/'\n",
    "validation_output_folder = './validation_prepared_images/'\n",
    "\n",
    "shutil.rmtree('./train_prepared_images')\n",
    "shutil.rmtree('./test_prepared_images')\n",
    "shutil.rmtree('./validation_prepared_images')\n",
    "\n",
    "os.mkdir('./train_prepared_images')\n",
    "os.mkdir('./train_prepared_images/cars')\n",
    "os.mkdir('./train_prepared_images/truck')\n",
    "\n",
    "os.mkdir('./test_prepared_images')\n",
    "os.mkdir('./test_prepared_images/cars')\n",
    "os.mkdir('./test_prepared_images/truck')\n",
    "\n",
    "os.mkdir('./validation_prepared_images')\n",
    "os.mkdir('./validation_prepared_images/cars')\n",
    "os.mkdir('./validation_prepared_images/truck')\n",
    "\n",
    "prepare_data (train_output_folder , 'train')\n",
    "prepare_data (test_output_folder , 'test')\n",
    "prepare_data (validation_output_folder , 'validation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importation des datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-04 14:40:32.444776: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/Users/thibaultberthet/Desktop/Deep-Learning-CPE-Project/.venv/lib/python3.8/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2292 files belonging to 2 classes.\n",
      "Found 666 files belonging to 2 classes.\n",
      "Found 327 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Définition des chemins pour les fichiers image\n",
    "train_dir = \"./train_prepared_images\"\n",
    "val_dir = \"./validation_prepared_images\"\n",
    "test_dir = \"./test_prepared_images\"\n",
    "\n",
    "# Définition des constantes \n",
    "batch_size = 32\n",
    "img_height = 224  # Hauteur de l'image (modifiable selon vos besoins)\n",
    "img_width = 224 \n",
    "\n",
    "train_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    label_mode='int',\n",
    "    color_mode='grayscale'\n",
    ")\n",
    "\n",
    "validation_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    val_dir,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    label_mode='int',\n",
    "    color_mode='grayscale'\n",
    ")\n",
    "\n",
    "test_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    label_mode='int',\n",
    "    color_mode='grayscale'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Création du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 222, 222, 32)      320       \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 111, 111, 32)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 109, 109, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPoolin  (None, 54, 54, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 52, 52, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPoolin  (None, 26, 26, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 86528)             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                2768928   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2861666 (10.92 MB)\n",
      "Trainable params: 2861666 (10.92 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "        layers.Conv2D(filters=32, kernel_size=(5, 5), activation='relu', input_shape=(img_width, img_height, 1)),\n",
    "        layers.MaxPooling2D((2,2)),\n",
    "        layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu', input_shape=(img_width, img_height, 1)),\n",
    "        layers.MaxPooling2D((2,2)),\n",
    "        layers.Conv2D(filters=128, kernel_size=(3, 3), activation='relu', input_shape=(img_width, img_height, 1)),\n",
    "        layers.MaxPooling2D((2,2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(32, activation='relu'),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(len(train_dataset.class_names), activation='softmax')\n",
    "    ])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "72/72 - 159s - loss: 2.4688 - accuracy: 0.5955 - val_loss: 0.6567 - val_accuracy: 0.6622 - 159s/epoch - 2s/step\n",
      "Epoch 2/5\n",
      "72/72 - 200s - loss: 0.6327 - accuracy: 0.6841 - val_loss: 0.6315 - val_accuracy: 0.6697 - 200s/epoch - 3s/step\n",
      "Epoch 3/5\n",
      "72/72 - 150s - loss: 0.5704 - accuracy: 0.7299 - val_loss: 0.6277 - val_accuracy: 0.6667 - 150s/epoch - 2s/step\n",
      "Epoch 4/5\n",
      "72/72 - 137s - loss: 0.6033 - accuracy: 0.7229 - val_loss: 0.6183 - val_accuracy: 0.6727 - 137s/epoch - 2s/step\n",
      "Epoch 5/5\n",
      "72/72 - 145s - loss: 0.5385 - accuracy: 0.7404 - val_loss: 0.7528 - val_accuracy: 0.6637 - 145s/epoch - 2s/step\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=validation_dataset,\n",
    "    epochs=5,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilisation des données de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 - 2s - loss: 0.6592 - accuracy: 0.6330 - 2s/epoch - 149ms/step\n",
      "Test Loss: 0.6592\n",
      "Test Accuracy: 0.6330\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_dataset, verbose=2)\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
